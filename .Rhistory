library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, prob = 0.99)
top_counts<-filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts, desc(count))
view(top_counts_sorted)
View(top_counts_sorted)
quantile(pack_sum$unique,probs=0.99)
top_unique<-filter(cran,unique>465)
top_unique<-filter(pack_sum,unique>465)
view(top_unique)
View(top_unique)
top_unique_sorted<-arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
submit()
View(result3)
submit()
submit()
submit
submit()
source('C:/Users/Corina/AppData/Local/Temp/RtmpiYRIqN/chain1.R')
submit()
submit()
submit()
submit()
quit
library(swirl)
ls
library(swirl)
swirl()
library(tidyr)
students
?gather
gather(students,sex, count,-grade)
students2
res<-gather(students2,sex_class, count, -grade)
res
?separate
separate(res,sex_class,sep="_")
separate(data=res,col=sex_class,into=c("sex","class"),sep="_")
separate(res,sex_class,c("sex","class"),"_")
separate(res,sex_class,c("sex","class"))
submit()
students3
submit()
submit()
?spread
submit()
extract_numeric("Class5")
extract_numeric("class5")
submit()
submit()
students4
submit()
submit()
submit
submit()
passed
failed
mutate(passed,status="passed")
passed<-mutate(passed,status="passed")
failed<-mutate(failed,status="failed")
bind_rows(passed, failed, id = NULL)
bind_rows(passed, failed)
sat
submit()
submit()
submit()
quit
exit
quit()
x<-rnorm(25)
x
x[x<.5]
x<.5
library(jpeg)
url<-'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(url,"tmp.jpg", mode = "wb")
d1<-readJPEG("tmp.jpg", native=TRUE)
quantile(d1,probs = c(0.3, 0.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "tt.csv")
ag<-read.csv("tt.csv")
names(ag)
agriculturalLogical<-ag$ACR == 3 & ag$AGS ==6
agriculturalLogical
which(agriculturalLogical)
read.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "gdp.csv")
gdp<-read.csv("gdp.csv")
names(gdp)
print(gdp)
download.file("https://d396qusza40orc.cloudfront.net/getdata$2Fdata$2FEDSTATS_country.csv", "edu.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata$2Fdata$2FEDSTATS_country.csv", "edu.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata$2Fdata$2FEDSTATS_Country.csv", "edu.csv")
edu<-read.csv2("https://d396qusza40orc.cloudfront.net/getdata$2Fdata$2FEDSTATS_Country.csv")
names(edu)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "edu.csv")
edu<-read.csv("edu.csv")
names(edu)
gdp$X
gdp<-read.csv("gdp.csv", skip=4, nrows=231)
gdp
gdp<-read.csv("gdp.csv", skip=4, nrows=215)
gdp
print(edu)
gdp<-read.csv("gdp.csv", skip=4, nrows=215, blank.lines.skip = TRUE)
gdp
edu
edu$CountryCode
edu$Long.Name
Z<-merge(gdp,edu, by.x = "X", by.y = "CountryCode", all=FALSE)
Z
names(Z)
head(Z)
sz<-sort(Z,desc(X.4))
sz<-Z[order(Z$X.4, na.last = TRUE, decreasing = TRUE),]
SZ
sz
head(sz,13)
names(gdp)
head(gdp)
sz<-Z[order(Z$X.1, na.last = TRUE, decreasing = TRUE),]
head(sz,13)
print(Z)
tail(Z)
unique(Z$X.1)
str(Z)
str(gdp)
library(dplyr)
names(Z)
group_by(Z, Z$Income.Group)
group_by(Z, 12)
tbl<-df_tbl(Z)
tbl<-tbl_df(Z)
tbl
group_b(tbl,"Income.Group")
group_by(tbl,"Income.Group")
group_by(tbl,Income.Group)
j<-group_by(tbl,Income.Group)
print(j)
Z
names(Z)
names(tbl)
class(tbl)
group_by(tbl, Income.Group)
gp<-group_by(tbl, Income.Group)
summarize(gp)
summarize(tbl)
tbl
rm("tbl")
class(Z)
group_by(Z, Income.Group)
ig<-group_by(Z, Income.Group)
summarize(ig)
ig
summarize(ig, mean(X.1))
class(tbl
)
tbl<-tbl_df(Z)
tbl
summarize(group_by(tbl, Income.Group))
ig<-group_by(tbl, Income.Group)
summarise(ig,mean(x.1))
summarise(ig,mean(X.1))
summarise(ig,mean(X.1, rm.na=TRUE))
summarise(ig,zzz = mean(X.1, na.rm =TRUE))
names(tbl)
head(tbl)
quantile(tbl$X.1)
quantile(tbl$X.1, na.rm = TRUE)
tbl2<-mutate(tbl,quant =quantile(X.1, na.rm = TRUE))
tbl2<-mutate(tbl,quant=quantile(tbl$X.1, na.rm = TRUE))
table(tbl$Income.Group, quantile(tbl$X.1, na.rm=TRUE))
table(tbl$Income.Group, tbl$X.1)
filter(tbl, tbl$Income.Group="Lower middle income" & tbl$X.1>143)
filter(tbl, tbl$Income.Group=="Lower middle income" & tbl$X.1>143)
filter(tbl, tbl$Income.Group=="Lower middle income" & tbl$X.1>152)
x
x
tbl
table(tbl$Income.Group, quantile(tbl$X.1))
table(tbl$Income.Group, quantile(tbl$X.1, na.rm=TRUE))
group_by(tbl, quantile(X.1), Income.Group)
group_by(tbl, quantile(X.1, na.rm = TRUE), Income.Group)
group_by(tbl, Income.Group, X.1)
quantile(tbl$X.1)
quantile(tbl$X.1, na.rm = TRUE)
quantile(tbl$X.1, probs=c(.2,.4,.6.,.8,1),na.rm = TRUE)
quantile(tbl$X.1, prob=c(0.2,0.4,0.6.,0.8,1), na.rm = TRUE)
quantile(tbl$X.1, probs = c(0.2, 0.4, 0.6, 0.8, 1), na.rm = TRUE)
filter(tbl, tbl$X.1>152 & tbl$Income.Group=="Lower middle income")
jjj<- filter(tbl, tbl$X.1>152 & tbl$Income.Group=="Lower middle income")
read(jjj)
print(jjj)
print(jjj$Income.Group)
jjj<- filter(tbl, tbl$X.1>152 & tbl$Income.Group=="Lower middle income", rm.na=TRUE)
print(jjj$Income.Group)
arrange(filter(tbl, tbl$Income.Group=="Lower middle income"), desc(tbl$X.1))
lmi<-filter(tbl, tbl$Income.Group=="Lower middle income")
arrange(lmi, desc(X.1))
srt<-arrange(lmi, desc(X.1))
head(srt, 20)
fil<- select(Z, X.1, Income.group)
fil<- select(Z, Z$X.1, Z$Income.group)
fil<- select(Z, Z$X.1, Z$Income.Group)
fil<- filter(Z, Z$Income.Group=="Lower middle income")
print(fil)
fil$X.1
fil$X.1>152
nrow(fil$X.1>152)
count(fil$X.1>152)
sum(fil$X.1>152, rm.na=TRUE)
summarise(fil$X.1>152)
count(fil$X.1>152, rm.na=TRUE)
table(tbl$X.1,tbl$Income.Group)
table(quantile(tbl$X.1, rm.na=true),tbl$Income.Group)
table(quantile(tbl$X.1, rm.na=TRUE),tbl$Income.Group)
table(quantile(tbl$X.1, na.rm =TRUE),tbl$Income.Group)
summarise(table(tbl$X.1,tbl$Income.Group), quantile(tbl$X.1, probs=c(.2,.4,.6,.8,1))
)
filter(arrange(tbl, tbl$X.1), tbl$Income.Group=="Lower middle income")
arrange(tbl, tbl$X.1)
filter(arrange(tbl, "X.1"), tbl$Income.Group=="Lower middle income")
arrange(tbl, "X.1")
arrange(tbl, X.1)
arrange(tbl, Income.Group, X.1)
filter(arrange(tbl,X.1), Income.Group=="Lower middle income")
filter(arrange(tbl,X.1), Income.Group=="Lower middle income")->yyy
yyy
arrange(filter(tbl, Income.Group=="Lower middle income"),X.1)->yyy
yyy
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day<-today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment<-now()
this_moment
minute(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
d2
dt2
ymd(dt2)
update(this_moment, hour=8, minutes=34, seconds=55)
update(this_moment, hours=8, minutes=34, seconds=55)
this_moment
this_moment<-update(this_moment, hours=12, minutes=16, seconds=12)
this_moment
nyc<=now("America/New_York")
nyc<-now("America/New_York")
nyc
depart<-nyc _ days(2)
depart<-nyc + days(2)
depart
depart<-nyc + hours(17) + minutes(34)
depart<-update(depart, hours = 17, minutes = 34)
depart
arrive<-depart + hours(15) + minutes(50)
?with_tz
arrive<-with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time<-with_tz(mdy("June 17, 2008", tzone="Asia/Hong_Kong"))
last_time<-mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long<-new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
acs<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", method="wb")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "survey.csv", method="wb")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "survey.csv")
head("survey")
head("survey.csv")
survey.csv
acs<-read.csv("survey.csv")
head(acs)
names(acs)
splitNames = strsplit(names(acs), "wgtp")
splitNames[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "gdp.csv")
gdp<-read.csv("gdp.csv")
head(gdp)
names(gdp)
gdp$X.3
amount<-sub(",", "", gdp$X.3)
amount
amount<-gsub(",", "", gdp$X.3)
amount
avg(amount, rm.na=TRUE)
average(amount, rm.na=TRUE)
mean(amount, rm.na=TRUE)
mean(amount)
mean(as.numeric(amount))
mean(as.numeric(amount), na.rm=TRUE)
test=is.na(gdp$X.3)
test
test=is.nuneric(gdp$X.3)
test=is.numeric(gdp$X.3)
test
head(gdp)
gdp$X
gdp$X.2
gdpdata<-gdp[7:219]
gdpdata<-gdp[7:219,]
gdpdata
gdpdata$X.3
gdpamount<-gdpdata$X.3[1:188]
gdpamount
gdpnum<-asnumeric(sub(",", "", gdpamount))
gdpnum<-as.numeric(sub(",", "", gdpamount))
gdpnum<-as.numeric(sub(",", "", gdpamount), na.rm=TRUE)
gdpnum<-as.numeric(sub(",", "", gdpamount), rm.na=TRUE)
gdpnum
gdpnum<-as.numeric(gsub(",", "", gdpamount), rm.na=TRUE)
gdpnum
mean(gdpnum)
gdp
grep(^United,gdp$X.2)
grep("United*",gdp$X.2)
grep("^United", gdp$X.2)
grep("*United", gdp$X.2)
grep("*United", gdp$X.2, value=TRUE)
gdp
amt<-gdp([5:219,3])
amt<-gdp[5:219,3]
amt
amt<-gdp[5:219,4]
amt
amt<-gdp[5:219,5]
amt
dollars<-as.numeric(gsub(",", "", amt[1:190]))
dollars
mean(dollars)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "edu.csv")
edu<-read.csv("edu.csv")
edu
gdpdata
head(edu)
names(edu)
head(gdpdata)
md<-merge(gdpdata, edu, by.x=X, by.y = CountryCode, all=FALSE)
md<-merge(gdpdata, edu, by.x="X", by.y = "CountryCode", all=FALSE)
md
names(md)
md$National.accounts.base.year
md$System.of.National.Accounts
head(md, 10)
md$Special.Notes
grep("Fiscal year end:", md$Special.Notes, ignore.case = TRUE, value = TRUE)
grep("Fiscal year end: June", md$Special.Notes, ignore.case = TRUE, value = TRUE)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
grep("^2012", sampleTimes)
nrows(grep("^2012", sampleTimes))
nrow(grep("^2012", sampleTimes))
y(sampleTimes)
library(lubridate)
y(sampleTimes)
wday(sampleTimes)
summary(wday(sampleTimes,label=TRUE))
format(date(sampleTimes), "%y%a"))
format(date(sampleTimes), "%y%a")
format(as.date(sampleTimes), "%y%a")
format(as.Date(sampleTimes), "%y%a")
summary(format(as.Date(sampleTimes), "%y%a"))
summarise(format(as.Date(sampleTimes), "%y%a"))
grep("12Mon", format(as.Date(sampleTimes), "%y%a"))
grep("12", format(as.Date(sampleTimes), "%y%a"))
nrow(grep("12", format(as.Date(sampleTimes), "%y%a")))
mmm<-format(as.Date(sampleTimes), "%y%a")
mmm
summary(mmm)
table(mmm)
yyyy<-format(as.Date(sampleTimes), "%y")
table(yyyy)
clear
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
source('C:/Users/Corina/WearableComputing/run_analysis.R')
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
run_analysis()
source('C:/Users/Corina/WearableComputing/run_analysis.R')
source('C:/Users/Corina/WearableComputing/run_analysis.R')
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
xxx<-group_by(totalTable, "Subject", "Activity")
featureCol
source('C:/Users/Corina/WearableComputing/run_analysis.R')
featuresFile<-"./UCI HAR Dataset/features.txt"
featuresTable<-read.table(featuresFile, sep="-", header=FALSE, fill = TRUE)
featureCol<-grep("mean()", featuresTable[,2], fixed=TRUE)
featureCol<-c(featureCol, grep("std()", featuresTable[,2], fixed=TRUE))
featureCol<-sort(featureCol)
activityFile<-"./UCI HAR Dataset/activity_labels.txt"
activityTbl<-read.table(activityFile)
testFile<-"./UCI HAR Dataset/test/X_test.txt"
testSubject<-"./UCI HAR Dataset/test/subject_test.txt"
testActivity<-"./UCI HAR Dataset/test/y_test.txt"
totalTestTbl<-read.table(testFile, header=FALSE, row.names = NULL)
testSubjectTbl<-read.table(testSubject, header=FALSE,row.names = NULL)
testActivityTbl<-read.table(testActivity, header = FALSE, row.names = NULL)
#Get the mean and standard deviation columns from the test data
testTbl<-totalTestTbl[,featureCol]
#Add activity lables to the test activity table.
testActivityTbl<-left_join(testActivityTbl, activityTbl, by = NULL)
#Merge test data into one table.
testData<-data.table(testSubjectTbl$V1, testActivityTbl$V2)
testData<-data.table(testData, testTbl)
#Import train data.
trainFile<-"./UCI HAR Dataset/train/X_train.txt"
trainSubject<-"./UCI HAR Dataset/train/subject_train.txt"
trainActivity<-"./UCI HAR Dataset/train/y_train.txt"
totaltrainTbl<-read.table(trainFile, header=FALSE, row.names = NULL)
trainSubjectTbl<-read.table(trainSubject, header=FALSE,row.names = NULL)
trainActivityTbl<-read.table(trainActivity, header = FALSE, row.names = NULL)
#Get the mean and standard deviation columns from the train data
trainTbl<-totaltrainTbl[, featureCol]
#Add activity lables to the train activity table.
trainActivityTbl<-left_join(trainActivityTbl, activityTbl, by = NULL)
#Merge train data into one table.
trainData<-data.table(trainSubjectTbl$V1, trainActivityTbl$V2)
trainData<-data.table(trainData, trainTbl)
#Merge the two datasets together.
totalTable<-rbind(testData, trainData)
#Add column names to the merged data
namesVector<-sub("\\s+$", "", paste(gsub("[[:space:]]", "", gsub("[[:digit:]]", "",featuresTable[featureCol,1])), gsub("()", "", featuresTable[featureCol,2], fixed=TRUE), featuresTable[featureCol, 3], sep=" "))
namesVector<-c("Subject", "Activity", namesVector)
names(totalTable)<-namesVector
source('C:/Users/Corina/WearableComputing/run_analysis.R')
dim(totalTable)
xxx<-group_by(totalTable, "Subject", "Activity")
xxx
summarise(xxx, mean())
summarise(xxx, n=mean(n))
summarise(xxx, n=mean(n, rm.na=TRUE))
summarise(xxx, n=mean(n, na.rm = =TRUE))
summarise(xxx, n = mean(n, na.rm = =TRUE))
summarise(xxx, n = mean(n, na.rm = TRUE))
class(xxx)
xxx
yyy <- tapply(totalTable, c("Subject", "Activity"), FUN=mean(), simplify = TRUE)
totalTable
yyy <- tapply(totalTable, c("Subject", "Activity"), FUN=mean(), simplify = TRUE)
yyy <- tapply(xxx, c("Subject", "Activity"), FUN=mean, simplify = TRUE)
yyy <- tapply(totalTable, c("Subject", "Activity"), FUN=mean, simplify = TRUE)
yyy <- tapply(totalTable, totalTable$Subject, totalTable$Activity, FUN=mean, simplify = TRUE)
yyy<-aggregate(totalTable, c("Subject", "Activity"), mean, simplify = TRUE)
yyy<-aggregate(c("Subject", "Activity"), totalTable, mean, simplify = TRUE)
yyy<-aggregate(totalTable, "Subject", mean, simplify = TRUE)
class(totalTable)
totalTable[,lapply(mean, "Subject", "Activity")]
totalTable[,lapply(mean, by="Subject")]
dataMelt<-melt(totalTable, id=c("Subject", "Activity"))
dataMelt
cast<-dcast(dataMelt, mean)
cast<-dcast(dataMelt, Subject + Activity ~ variable, mean)
cast
dataMelt
dataMelt<-melt(totalTable, id=c("Subject", "Activity"))
names(dataMelt)
groupedData<-group_by(dataMelt, Subject, Activity, variable)
groupedData
groupedData<-group_by(dataMelt, Subject, Activity, variable)
summary<-summarise(groupedData, mean(value))
summary
class(summary)
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
run_analysis()
source('C:/Users/Corina/WearableComputing/run_analysis.R')
run_analysis()
